# Transformer from Scratch (å­¦ä¹ ç‰ˆ)

æœ¬ä»“åº“å†…å®¹åŸºäº [Wayland Zhang](https://github.com/waylandzhang) è€å¸ˆçš„å¼€æºä»“åº“å’Œè¯¾ç¨‹è§†é¢‘æ•´ç†å­¦ä¹ ã€‚  
åŸå§‹å®ç°è¯·å‚è€ƒï¼š[nanoGPT](https://github.com/karpathy/nanoGPT) å’Œ [å¼ è€å¸ˆçš„ä»“åº“](https://github.com/waylandzhang/transformer-from-scratch)ã€‚  

> âš ï¸ æœ¬ä»“åº“ä»…ä½œä¸ªäººå­¦ä¹ ä¸è¯¾ç¨‹è·Ÿç»ƒä½¿ç”¨ï¼Œä¸æ¶‰åŠåŸåˆ›è´¡çŒ®ï¼Œå¦‚éœ€ä½¿ç”¨æˆ–å¼•ç”¨ï¼Œè¯·ä»¥åŸä»“åº“ä¸ºå‡†ã€‚

---

## é¡¹ç›®ç®€ä»‹

è¿™æ˜¯ä¸€ä¸ª **Transformer æ¶æ„çš„ Large Language Model (LLM)** è®­ç»ƒ Demoï¼Œä»…ä½¿ç”¨ _çº¦ 240 è¡Œä»£ç _ã€‚  

é€šè¿‡è¯¥ Demoï¼Œå¯ä»¥ä»é›¶å¼€å§‹ç†è§£å¦‚ä½•ç”¨ PyTorch è®­ç»ƒä¸€ä¸ªç®€å•çš„ LLMã€‚  
ä»£ç ç®€æ´æ˜“æ‡‚ï¼Œé€‚åˆä½œä¸ºå…¥é—¨å­¦ä¹ ææ–™ã€‚

- è®­ç»ƒæ•°æ®ï¼šçº¦ 450 KB [sample textbook](https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt)  
- æ¨¡å‹å¤§å°ï¼šçº¦ 51M  
- å‚æ•°é‡ï¼šçº¦ 1.3M  
- ç¡¬ä»¶ï¼šå•å° i7 CPU  
- è®­ç»ƒæ—¶é—´ï¼šçº¦ 20 åˆ†é’Ÿ

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

# Transformer from Scratch (å­¦ä¹ ç‰ˆ)

æœ¬ä»“åº“åŸºäº [Wayland Zhang](https://github.com/waylandzhang) è€å¸ˆçš„å¼€æºä»“åº“å’Œè¯¾ç¨‹è§†é¢‘æ•´ç†ï¼Œä»…ä½œå­¦ä¹ ä¸è·Ÿç»ƒä½¿ç”¨ã€‚åŸå§‹å®ç°è¯·å‚è€ƒï¼š[nanoGPT](https://github.com/karpathy/nanoGPT) å’Œ [å¼ è€å¸ˆçš„ä»“åº“](https://github.com/waylandzhang/transformer-from-scratch)ã€‚

> âš ï¸ æœ¬ä»“åº“ä»…ä½œä¸ªäººå­¦ä¹ ç”¨é€”ï¼Œå¦‚éœ€ä½¿ç”¨æˆ–å¼•ç”¨ï¼Œè¯·ä»¥åŸä»“åº“ä¸ºå‡†ã€‚

è¿™æ˜¯ä¸€ä¸ª Transformer æ¶æ„çš„ Large Language Model (LLM) è®­ç»ƒ Demoï¼Œä»…ä½¿ç”¨çº¦ 240 è¡Œ PyTorch ä»£ç ã€‚é€šè¿‡è¯¥ Demoï¼Œå¯ä»é›¶å¼€å§‹ç†è§£å¦‚ä½•è®­ç»ƒ LLMï¼Œå¹¶è§‚å¯Ÿè®­ç»ƒä¸ç”Ÿæˆæ•ˆæœã€‚è®­ç»ƒæ•°æ®ä¸ºçº¦ 450 KB [sample textbook](https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt)ï¼Œæ¨¡å‹å¤§å°çº¦ 51Mï¼Œå‚æ•°é‡çº¦ 1.3Mï¼Œæˆ‘åœ¨å•å° i7 CPU ä¸Šè¿è¡Œè®­ç»ƒæ—¶é—´çº¦ 20 åˆ†é’Ÿã€‚

## å®‰è£…ä¾èµ–

pip install numpy requests torch tiktoken

## è®­ç»ƒæ¨¡å‹

python model.py

é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ•°æ®é›†åˆ° data æ–‡ä»¶å¤¹ï¼Œæ¨¡å‹å°†åœ¨æ•°æ®é›†ä¸Šå¼€å§‹è®­ç»ƒï¼Œå¹¶åœ¨æ§åˆ¶å°è¾“å‡ºè®­ç»ƒä¸éªŒè¯ Lossï¼Œä¾‹å¦‚ï¼š

Step: 0 Training Loss: 11.68 Validation Loss: 11.681  
Step: 20 Training Loss: 10.322 Validation Loss: 10.287  
Step: 40 Training Loss: 8.689 Validation Loss: 8.783  
...

5000 æ¬¡è¿­ä»£åï¼ŒLoss ä¼šä¸‹é™åˆ°çº¦ 2.807ï¼Œæ¨¡å‹ä¼šä¿å­˜ä¸º model-ckpt.ptã€‚è®­ç»ƒå®Œæˆåä¼šåœ¨æ§åˆ¶å°è¾“å‡ºæ¨¡å‹ç”Ÿæˆæ–‡æœ¬ç¤ºä¾‹ï¼Œä¾‹å¦‚ï¼š

The salesperson to identify the other cost savings interaction towards a nextProps audience, ...

æç¤ºï¼šå¯ä»¥ä¿®æ”¹ model.py é¡¶éƒ¨è¶…å‚æ•°ï¼Œè§‚å¯Ÿè®­ç»ƒæ•ˆæœçš„å˜åŒ–ã€‚

## ğŸ“’ Step-by-Step Notebook

æœ¬ä»“åº“æä¾› step-by-step.ipynbï¼Œé€æ­¥å±•ç¤º Transformer çš„è®¡ç®—è¿‡ç¨‹ã€‚è¿è¡Œå‰éœ€è¦å®‰è£…é¢å¤–ä¾èµ–ï¼š

pip install matplotlib pandas

Notebook ä¸­åŒ…å«ï¼š

- è¾“å…¥åµŒå…¥çŸ©é˜µç¤ºä¾‹  
- ä½ç½®ç¼–ç å¯è§†åŒ–  
- æ³¨æ„åŠ›çŸ©é˜µä¸ Mask æ“ä½œå¯è§†åŒ–  

é€šè¿‡è¿™äº›å¯è§†åŒ–è¿‡ç¨‹ï¼Œå¸®åŠ©ç†è§£ Transformer Decoder-only æ¶æ„çš„è®­ç»ƒæµç¨‹ã€‚

## ğŸ“‚ å…¶å®ƒå†…å®¹

/GPT2 ç›®å½•åŒ…å«ç¤ºä¾‹ä»£ç ï¼Œæ¼”ç¤ºå¦‚ä½•å¾®è°ƒé¢„è®­ç»ƒ GPT2 æ¨¡å‹å¹¶è¿›è¡Œæ¨ç†ã€‚

## ğŸ“š æ¨èé˜…è¯»

- [nanoGPT](https://github.com/karpathy/nanoGPT) â€” Andrej Karpathy çš„ç»å…¸ GPT æ•™ç¨‹  
- [Transformers from Scratch](https://blog.matdmiller.com/posts/2023-06-10_transformers/notebook.html) â€” Mat Miller çš„ç®€æ´å®ç°  
- [Attention is All You Need](https://arxiv.org/abs/1706.03762) â€” Transformer åŸå§‹è®ºæ–‡  
- [Transformer Architecture: LLM From Zero-to-Hero](https://medium.com/@waylandzhang/transformer-architecture-llms-zero-to-hero-98b1ee51a838) â€” å¼ è€å¸ˆçš„è®²è§£æ–‡ç« 

ğŸ“Œ è¯´æ˜  
æœ¬ä»“åº“ä»…ä½œå­¦ä¹ ç”¨é€”ï¼Œå†…å®¹æ¥è‡ªå¼ è€å¸ˆå…¬å¼€èµ„æ–™ä¸è¯¾ç¨‹ï¼Œå¼•ç”¨æˆ–ä½¿ç”¨è¯·ä»¥åŸä»“åº“ä¸ºå‡†.


